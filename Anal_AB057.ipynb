{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of an *in vivo* patch clamp recording experiment\n",
    "mouse name: 057  \n",
    "task: NearFarLong  \n",
    "experimentalist: Berci Andrásfalvy\n",
    "\n",
    "### 0. Preprocessing the data\n",
    "The goal of preprocessing is to load the data recorded by the Axon Instruments software, perform the action potential detection and save it in a way that it can be loaded into the behavioral analysis routines. The only problematic part is the spike detection, since the baseline voltage fluctuates a lot and AP amplitudes are not very high, so the amplitudes are comparable to the baseline fluctuations. These fluctuation can be removed by a high pass filter, still the amplitude of the high frequency noise can be similar to the amplitude of the APs. Therefore this step can not be fully automatized. \n",
    "\n",
    "In this case I did the preprocessing using custom-written python scripts that seemed to work fine for this particular recording. The plan is that Bazsi will write a program that allows Berci to change the parameters of the voltage filter and the threshold of the spike detection to best match the particular recording session. This will be the same program as the one that saves the behavioral and the e-phys data in igor-compatible format. I also downsampled the original recordings from 50 000 Hz to 5000 Hz - this should be fine for most of the analysis we want to implement here. \n",
    "\n",
    "### 1. Load the necessary object class\n",
    "To analyse spatial tuning of the recorded cells we use the same program as we use for the *in vivo* imaging data. The name of the functions reflect their primary usage for imaging. The main difference here is that \n",
    "1. We have higher time resolution voltage recording instead of the fluorescence signal.\n",
    "2. For spikes, we have the actual spike times and not just spike probabilities or inferred spike times\n",
    "3. When we calculate spatial tuning we use the original, 5000 Hz temporal resolution. However, when I calculate shuffling I downsample all data to 50 Hz, and compare the actual data with the shuffled at this, lower resolution. This is mainly due to a memory issue: Shuffling the spike data recorded at 5000 Hz for 300 s (1e6 datapoint) with 1000 shuffles is 1e9 datapoints is a few GB array even for a single neuron. Storing such large array in memory could slow down the calculation. \n",
    "\n",
    "We use a custom-made class, ImagingSessionData, that will contain all behavioral and imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImageAnal import *\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tell python where the data is\n",
    "The required file structure is the following:  \n",
    "- All data should be in the data folder\n",
    "- Within the data folder separate subfolders are needed for each mouse. Folder name starts with the **name** of the mouse.\n",
    "- For each mouse there should be a single folders containing **both** the **e-phys** data and the **behavioral** data.\n",
    "- The folder is named as `MouseName_TaskName` - so we need a separate folder for each different task\n",
    "- The behavioral log files are in separate subfolders named by the experiment's start time within the behavioral folder - e.g. `2021-02-03_10-15-50`\n",
    "- There are several recordings (traces) within the same session. They should be numbered - `imaging_logfile_name` is the number we want to process.\n",
    "- We need to tell python that the e-phys files are in the same folder. Remember, python thinks that these ar eimaging files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = os.getcwd() + '/' #current working directory - look for data and strings here!\n",
    "date_time = '2021-06-25_13-04-27' # date and time of the imaging session\n",
    "name = 'AB057' # mouse name\n",
    "task = 'NearFarLong' # task name\n",
    "\n",
    "suite2p_folder = datapath + 'data/' + name + '_NearFarLong/2021-06-25_13-04-27/' # the e-phys files should be here\n",
    "\n",
    "## the name and location of the trigger voltage file\n",
    "TRIGGER_VOLTAGE_FILENAME = suite2p_folder + 'Trigger_0001.csv'\n",
    "\n",
    "## the name and location of the imaging log file - this is the number of the recording session...\n",
    "imaging_logfile_name = '0001' # elfiz_session_number\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load all the data - this taks ~20 secs in my computer\n",
    "Python looks for the data in the specified folders. It loads the behavioral data (position, lick and rewards) as well as the imaging data. It calculates the activity of the cells as a function of position in the different corridors and calculates their spatial tuning measures and corridor selectivity.  \n",
    "The name of the object that contains all the data is `D1` here - Data 1.  \n",
    "\n",
    "**Important**: to tell python that you want to load e-phys data, you need to write at the end that `elfiz = True`  \n",
    "\n",
    "**Important 2.**: Berci recorded from the same mouse for ~2 hours, and there are almost 1000 laps. Loading all the data needs a lots of memory, and takes forever. So I selected only the 20-80 laps that contain the laps during the current recordings. Iy you want to analyse a different recording, then you need to load the appropriate traces!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigger logfile loaded\n",
      "trigger voltage signal loaded\n",
      "triggers after: 22\n",
      "n_extra_indexes 5\n",
      "candidate log indexes [48, 147, 246, 344, 345, 443, 444, 542, 543, 641, 642, 740, 839, 938]\n",
      "min recorded trigger length: 0.4898000000000007\n",
      "relevant behavior located, lap time of the first frame: 1360.813762 , log reference index: 48\n",
      "elfiz data loaded\n",
      "elfiz time axis loaded\n",
      "ExpStateMachineLog time interval > 1s:  293  times\n",
      "############################################################\n",
      "substage change detected!\n",
      "first lap in substage  ['1'] is lap 0 , which started at t 1051.0210371398189\n",
      "the time of the change in imaging time is:  -309.7927248601811\n",
      "############################################################\n",
      "calculating rate, reliability and Fano factor...\n",
      "calculating Skaggs spatial info...\n",
      "calculating proportion of active laps...\n",
      "calculating proportion of active laps based on dF/F ...\n",
      "calculating linear tuning specificity ...\n",
      "calculating rate, reliability and Fano factor...\n",
      "calculating Skaggs spatial info...\n",
      "calculating proportion of active laps...\n",
      "calculating proportion of active laps based on dF/F ...\n",
      "calculating linear tuning specificity ...\n",
      "calculating corridor selectivity ...\n",
      "calculating corridor similarity ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ubi/Projects/KOKI/VR/MiceData/utils.py:17: RuntimeWarning: invalid value encountered in true_divide\n",
      "  r = np.divide(r_num, r_den, out=out_vec, where=vec_nonzero)\n"
     ]
    }
   ],
   "source": [
    "# 3. load all the data - this taks ~20 secs in my computer\n",
    "D1 = ImagingSessionData(datapath, date_time, name, task, suite2p_folder, imaging_logfile_name, TRIGGER_VOLTAGE_FILENAME, selected_laps=np.arange(20,80), speed_threshold=5, randseed=123, elfiz=True)#, startendlap=[27, 99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The behavior is divided into laps (trials or runs). You can check the **number of laps** and which lap is associated with imaging data in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "[28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50]\n"
     ]
    }
   ],
   "source": [
    "print(D1.n_laps)\n",
    "print(D1.i_Laps_ImData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 229 laps and laps 83-138 contain imaging data.  \n",
    "### 4. Plotting the behavioral data\n",
    "You can plot the behavioral data of the session. This mouse runs a lot, but the performance is not great: it lick almost everywhere and does not systematically slow down before reward zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e77297515d74ccfa06b239cd0eb8e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#D1.plot_session()\n",
    "D1.plot_session(selected_laps=D1.i_Laps_ImData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  Plot the activity lap by lap\n",
    "We can also plot the lap by lap activity of a the recorded cell. Again, there are several options, but first is to plot the Vm and the spikes as a function of time. To achieve this, we need to set `signal  = 'dF' `.  \n",
    "\n",
    "Different colors are different laps. Solid line is the recorded Vm - gaps correspond to calibration pulses that have been removed during preprocessing. Traces are shifted so that their minimum is at the corresponding point in the y-axis. Vm curves are transparentm so they do not cover each other. Open square is the reward time and colored dotes are the spikes - each at the y coordinate at the given lap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3210f2a22c42a1a109dd03250df41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D1.plot_cell_laps(cellid=0, signal='dF') ## look at lap 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in lap 6 in corridor 15 the cell fired a lots of spikes. We can check the index of this lap using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lap # in corridor 15 with imaging data;    lap # within session\n",
      "0 \t 28\n"
     ]
    }
   ],
   "source": [
    "D1.get_lap_indexes(corridor=15, i_lap=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the activity in this particular lap. The argument `th = -0.5` tells python to include all cells with spike count larger than `-0.5` which is all neurons. `flue = True` means that the flourescence (voltage) is also plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d5751fd4614d54a2fec05fcec2aca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "/Users/ubi/Projects/KOKI/VR/MiceData/ImageAnal.py:2119: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n",
      "/Users/ubi/Projects/KOKI/VR/MiceData/ImageAnal.py:2119: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "D1.ImLaps[47].plot_tx(th=-0.5, fluo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lap, the animal was running during the spikes, but this not true for all laps. For examplde, in lap 1 in corridor 15 the animal was still during most of the big burst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lap # in corridor 15 with imaging data;    lap # within session\n",
      "1 \t 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0640a9e44604ba98bc1e0a43b339538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    }
   ],
   "source": [
    "D1.get_lap_indexes(corridor=15, i_lap=1) \n",
    "D1.ImLaps[30].plot_tx(th=-0.5, fluo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the firing rate a s afunction of the position. Note, that here we only include timesteps where the speed was larger than 5 cm/s. It is possible to change the speed threshold at the beginning of the analysis when defining the ImagingSessionData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb60b8ed9e7f47e5949e16a0df9123f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D1.plot_cell_laps(cellid=0, signal='rate') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Calculate significance of tuning by shuffling the imaging data \n",
    "Finally, we can calculate the significance of the tuning of the cell by shuffling its activity 1000 times. This takes a while, but since we only do this for 1 cell it is not too long. But it is only calculated once, and then it automatically reads it from a file. The cell is not significantly spatially tuned, not corridor selective and does not show similar spatial activity in the two corridors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading shuffling P-values from file...\n",
      "0\n",
      "1\n",
      "selective cells: []\n",
      "similar cells: []\n"
     ]
    }
   ],
   "source": [
    "cellids = np.array([0])\n",
    "D1.calc_shuffle(cellids, 1000, 'shift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([], dtype=int64), array([], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "print(D1.tuned_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session parameters written into file:  cell_properties_corridor_14_N1.csv\n",
      "cell properties for corridor 14  saved into file:  /Users/ubi/Projects/KOKI/VR/MiceData/data/AB057_NearFarLong/2021-06-25_13-04-27/analysed_data/cell_properties_corridor_14_N1.csv\n",
      "Session parameters written into file:  cell_properties_corridor_15_N1.csv\n",
      "cell properties for corridor 15  saved into file:  /Users/ubi/Projects/KOKI/VR/MiceData/data/AB057_NearFarLong/2021-06-25_13-04-27/analysed_data/cell_properties_corridor_15_N1.csv\n",
      "Session parameters written into file:  ratemaps_corridor_14_N1.csv\n",
      "ratemap for corridor 14  saved into file:  /Users/ubi/Projects/KOKI/VR/MiceData/data/AB057_NearFarLong/2021-06-25_13-04-27/analysed_data/ratemaps_corridor_14_N1.csv\n",
      "Session parameters written into file:  ratemaps_corridor_15_N1.csv\n",
      "ratemap for corridor 15  saved into file:  /Users/ubi/Projects/KOKI/VR/MiceData/data/AB057_NearFarLong/2021-06-25_13-04-27/analysed_data/ratemaps_corridor_15_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_28_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_29_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_30_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_31_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_32_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_33_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_34_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_35_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_36_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_37_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_38_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_39_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_40_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_41_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_42_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_43_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_44_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_45_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_46_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_47_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_48_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_49_N1.csv\n",
      "Session parameters written into file:  lapdata_lap_50_N1.csv\n",
      "lapdata saved into file: /Users/ubi/Projects/KOKI/VR/MiceData/data/AB057_NearFarLong/2021-06-25_13-04-27/analysed_data/lapdata_lap_50_N1.csv\n"
     ]
    }
   ],
   "source": [
    "D1.save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
